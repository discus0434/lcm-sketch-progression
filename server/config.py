from dataclasses import dataclass
from typing import Literal


@dataclass
class Config:
    """
    The configuration for the LCM sketch progression server.
    """

    ####################################################################
    # General
    ####################################################################
    # Target resolution is the resolution of the image that will be
    # returned to the client.
    # If use_super_resolution is True, the target resolution will be
    # multiplied by superres_scale.
    target_resolution: int = 512

    ####################################################################
    # Server
    ####################################################################
    # In most cases, you should leave this as it is.
    host: str = "0.0.0.0"
    port: int = 9090
    workers: int = 1

    ####################################################################
    # Acceleration
    ####################################################################
    # torch_compile will compile the model, which will make it faster,
    # but will require more memory.
    torch_compile: bool = True
    # xformers will use the xformers library to make the model use less
    # memory.
    # If your GPU has less than 8GB of VRAM, you should set this to
    # True. Otherwise, you should set this to False.
    xformers: bool = False
    device: Literal["cpu", "cuda"] = "cuda"

    ####################################################################
    # Prompt
    ####################################################################
    # The prompt model will be used to generate the prompt for the LCM
    # guidance.
    prompt_model_id: str = "Gustavosta/MagicPrompt-Stable-Diffusion"

    ####################################################################
    # LCM
    ####################################################################
    # The LCM model will be used to generate the image.
    lcm_model_id: str = "SimianLuo/LCM_Dreamshaper_v7"
    vae_model_id: str = "madebyollin/taesd"
    # Torch dtype of the LCM model. If you have only CPU or nice GPU,
    # you can set this to float32. Otherwise, you should set this to
    # float16.
    dtype: Literal["float32", "float16"] = "float16"
    # The resolution of the image that will be generated by the LCM.
    # The higher the resolution, the slower the generation will be and
    # the more memory it will require. However, the output image will
    # be higher quality.
    generation_resolution: int = 512
    # Initial prompt for the LCM. This prompt will be used to generate
    # images in the first 45 seconds.
    initial_prompt: str = "psychedelic structure, high quality"
    # Negative prompt for the LCM. This prompt is unchanged throughout.
    negative_prompt: str = "jpeg artifacts, low quality, bad quality, bad compression, low resolution, blurry"
    # The number of inference steps for the LCM. The higher the number,
    # the slower the generation will be. However, the output image will
    # be higher quality.
    inference_steps: int = 2
    # The number of inference steps for the LCM. The higher the number,
    # the change in the image will be more aggressive.
    strength: float = 0.4
    # Guidance scale for the LCM. The higher the number, the more
    # aligned the image will be with the prompt.
    guidance_scale: float = 8.0
    # LDM pretends to denoise the number of steps below.
    # IDK what this actually affects.
    original_inference_steps: int = 50

    ####################################################################
    # Super Resolution
    ####################################################################
    # Whether to use super resolution. If this is True, the image will
    # be generated at a lower resolution and then upscaled to the
    # target resolution.
    use_super_resolution: bool = False
    # The scale of the super resolution. If you set this to 2,
    # target_resolution must be equal to generation_resolution * 2.
    superres_scale: Literal[2, 4, 8] = 2
    # The model path used for super resolution.
    realesrgan_model_path_format: str = "/app/models/RealESRGAN_x{}.pth"

    def __post_init__(self):
        if self.xformers and self.torch_compile:
            raise ValueError("xformers and torch_compile cannot be both True")

        if self.use_super_resolution:
            if not (
                self.target_resolution
                == self.generation_resolution * self.superres_scale
            ):
                raise ValueError(
                    "target_resolution must be equal to generation_resolution * superres_scale."
                )
        if not self.use_super_resolution:
            if not self.target_resolution == self.generation_resolution:
                raise ValueError(
                    "target_resolution must be equal to generation_resolution, if use_super_resolution is False."
                )
